{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Sentiment analysis\n",
    "\n",
    "For the first task in Part 2, a custom model was developed to \n",
    "apply sentiment analysis to the tweets streamed in part 1.\n",
    "\n",
    "The training data was the *Sentiment-140* dataset \n",
    "(Go, Bhayaniand Huang, 2009), acquired via\n",
    " [kaggle](https://www.kaggle.com/kazanova/sentiment140).\n",
    "\n",
    "## Load and sample data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   polarity                                       preprocessed\n0         0   man thats insane im waiting for my g jailbrea...\n1         0  bright and early day  last full day in key wes...\n2         0  megafail on the chair front though  brought my...\n3         0                                  isnt feelin well \n4         0  itsucks when you are the only one home and get...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>polarity</th>\n      <th>preprocessed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>man thats insane im waiting for my g jailbrea...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>bright and early day  last full day in key wes...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>megafail on the chair front though  brought my...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>isnt feelin well</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>itsucks when you are the only one home and get...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 19
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from brexittweets.custom_funcs.process_text_functions import preprocess_training_data\n",
    "from brexittweets.config import training_data_path\n",
    "\n",
    "# check which version of the training data is available:\n",
    "training_data_path = training_data_path\n",
    "names = ['polarity', 'id', 'date', 'flag', 'user', 'text']\n",
    "classified_tweets = pd.read_csv(training_data_path, names=names, encoding='ISO-8859-1')\n",
    "\n",
    "# apply the same preprocessing as was applied to streaming tweets\n",
    "classified_tweets['preprocessed'] = classified_tweets['text'].map(preprocess_training_data)\n",
    "classified_tweets['polarity'].unique()\n",
    "    \n",
    "    \n",
    "# tweets ordered by sentiment, take sample from the middle\n",
    "classified_tweets = classified_tweets.iloc[650000:950000,[0,-1]]\n",
    "\n",
    "classified_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Get the polarity of the Tweets from the classified dataset. Check that we have equal numbers of positive (4.0) and\n",
    " negative (0.0) Tweets.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Unique values: [0 4]\n",
      "Number of negative Tweets: 300000\n",
      "Number of negative Tweets: 300000\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "Y = classified_tweets.pop('polarity')\n",
    "print(f'Unique values: {Y.unique()}')\n",
    "print(f'Number of negative Tweets: {len(Y==0)}')\n",
    "print(f'Number of negative Tweets: {len(Y==4)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Apply text preprocessing\n",
    "\n",
    "For each tweet, apply tokenization, stemming, and lemmatization \n",
    "so that all forms of each unique word are grouped together. \n",
    "\n",
    "Then count the occurrence of each word to create a dictionary of \n",
    "features for each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['that', 'insan', 'wait', 'jailbreak', 'miss', 'flexibl']"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 4
    }
   ],
   "source": [
    "from brexittweets.custom_funcs.process_text_functions import tokenize_tag,stem_lemmatize\n",
    "\n",
    "preprocessed_tokenized = []\n",
    "\n",
    "for tweet in classified_tweets['preprocessed']:\n",
    "\ttokenized_tweet = tokenize_tag(tweet)\n",
    "\tpreprocessed_tokenized.append(stem_lemmatize(tokenized_tweet))\n",
    "    \n",
    "#Check that tokenisation, stemming and lemmatization has worked.\n",
    "preprocessed_tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def get_features(text: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Count each unique word in a tweet and return dictionary of words and their counts \n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    for word in text:\n",
    "        # Create word key and initialise as 1\n",
    "        if word not in features.keys():\n",
    "            features[word] = 1\n",
    "        else:\n",
    "            # Increase count of word\n",
    "            features[word] = features[word] + 1\n",
    "    return features\n",
    "\n",
    "# Create list in which to store word counts\n",
    "all_features = []\n",
    "\n",
    "# Get word count for every tweet\n",
    "for feature, label in zip([get_features(tweet) for tweet in preprocessed_tokenized], Y):\n",
    "    all_features.append((feature,label))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "300000"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    }
   ],
   "source": [
    "len(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Split data\n",
    "\n",
    "The training data is ordered by sentiment, so a sample will be taken\n",
    "from the middle to be the training data.\n",
    "\n",
    "The training data is supplied to a NaiveBayesClassifer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "# Split data into training and testing.\n",
    "\n",
    "training_data = all_features[45000:255000]\n",
    "testing_data = all_features[0:45000] + all_features[255000:]\n",
    "\n",
    "nbclassifier = NaiveBayesClassifier.train(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Examine the classifier\n",
    "\n",
    "We can examine the classifier to find out which features are most influential, and \n",
    "to predict sentiment for the testing set and evaluate accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Most Informative Features\n",
      "                  farrah = 1                   0 : 4      =    321.0 : 1.0\n",
      "                    iran = 1                   0 : 4      =    114.6 : 1.0\n",
      "              squarespac = 1                   0 : 4      =     97.7 : 1.0\n",
      "                  hayfev = 1                   0 : 4      =     73.0 : 1.0\n",
      "            followfriday = 1                   4 : 0      =     69.4 : 1.0\n",
      "                  divorc = 1                   0 : 4      =     52.6 : 1.0\n",
      "                   cramp = 1                   0 : 4      =     50.3 : 1.0\n",
      "                wolverin = 1                   4 : 0      =     44.6 : 1.0\n",
      "                  glasto = 1                   0 : 4      =     41.7 : 1.0\n",
      "                  father = 2                   0 : 4      =     40.6 : 1.0\n",
      "                    ceci = 1                   0 : 4      =     33.7 : 1.0\n",
      "                  father = 1                   0 : 4      =     30.0 : 1.0\n",
      "                  booooo = 1                   0 : 4      =     27.0 : 1.0\n",
      "                 noooooo = 1                   0 : 4      =     27.0 : 1.0\n",
      "                      no = 1                   0 : 4      =     25.7 : 1.0\n",
      "                homesick = 1                   0 : 4      =     21.7 : 1.0\n",
      "                 solstic = 1                   0 : 4      =     21.0 : 1.0\n",
      "                nooooooo = 1                   0 : 4      =     21.0 : 1.0\n",
      "                   sicki = 1                   0 : 4      =     21.0 : 1.0\n",
      "                 unhappi = 1                   0 : 4      =     21.0 : 1.0\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "nbclassifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 features  polarity  classify\n650000  {'that': 1, 'insan': 1, 'wait': 1, 'jailbreak'...         0         0\n650001  {'bright': 1, 'earli': 1, 'west': 1, 'dont': 1...         0         0\n650002  {'megafail': 1, 'chair': 1, 'bring': 1, 'camp'...         0         0\n650003                           {'isnt': 1, 'feelin': 1}         0         0\n650004  {'itsuck': 1, 'home': 1, 'stuck': 1, 'bathroom...         0         0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>features</th>\n      <th>polarity</th>\n      <th>classify</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>650000</th>\n      <td>{'that': 1, 'insan': 1, 'wait': 1, 'jailbreak'...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>650001</th>\n      <td>{'bright': 1, 'earli': 1, 'west': 1, 'dont': 1...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>650002</th>\n      <td>{'megafail': 1, 'chair': 1, 'bring': 1, 'camp'...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>650003</th>\n      <td>{'isnt': 1, 'feelin': 1}</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>650004</th>\n      <td>{'itsuck': 1, 'home': 1, 'stuck': 1, 'bathroom...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 9
    }
   ],
   "source": [
    "# turn testing data into DataFrame\n",
    "test_df = pd.DataFrame(data = {'features': [feature[0] for feature in testing_data],\n",
    "                               'polarity': Y[0:45000].append(Y[255000:])})\n",
    "\n",
    "# Add column of predicted values.\n",
    "test_df['classify']=test_df['features'].apply(nbclassifier.classify)\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 features  polarity  classify\n650000  {'that': 1, 'insan': 1, 'wait': 1, 'jailbreak'...         0         0\n650001  {'bright': 1, 'earli': 1, 'west': 1, 'dont': 1...         0         0\n650002  {'megafail': 1, 'chair': 1, 'bring': 1, 'camp'...         0         0\n650003                           {'isnt': 1, 'feelin': 1}         0         0\n650004  {'itsuck': 1, 'home': 1, 'stuck': 1, 'bathroom...         0         0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>features</th>\n      <th>polarity</th>\n      <th>classify</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>650000</th>\n      <td>{'that': 1, 'insan': 1, 'wait': 1, 'jailbreak'...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>650001</th>\n      <td>{'bright': 1, 'earli': 1, 'west': 1, 'dont': 1...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>650002</th>\n      <td>{'megafail': 1, 'chair': 1, 'bring': 1, 'camp'...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>650003</th>\n      <td>{'isnt': 1, 'feelin': 1}</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>650004</th>\n      <td>{'itsuck': 1, 'home': 1, 'stuck': 1, 'bathroom...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 10
    }
   ],
   "source": [
    "# turn testing data into DataFrame\n",
    "test_df = pd.DataFrame(data = {'features': [feature[0] for feature in testing_data],\n",
    "                               'polarity': Y[0:45000].append(Y[255000:])})\n",
    "\n",
    "# Add column of predicted values.\n",
    "test_df['classify']=test_df['features'].apply(nbclassifier.classify)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "True positives: 32561\n",
      "True negatives: 34240\n",
      "False positives: 10760\n",
      "False negatives: 12439\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "test_df['sum'] = test_df['polarity'] + test_df['classify']\n",
    "test_df['diff'] = test_df['polarity'] - test_df['classify']\n",
    "\n",
    "TP = len(test_df[test_df['sum']==8]) # true positives\n",
    "TN = len(test_df[test_df['sum']==0]) # true negatives\n",
    "FP = len(test_df[test_df['diff']==-4]) # false positives\n",
    "FN = len(test_df[test_df['diff']==4]) # false negatives\n",
    "all = TP+TN+FP+FN\n",
    "\n",
    "print(f'True positives: {TP}\\nTrue negatives: {TN}\\nFalse positives: {FP}\\nFalse negatives: {FN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Classifer metrics:\n",
      "--------------------\n",
      "Accuracy: 0.7422333333333333\n",
      "Recall: 0.7235777777777778\n",
      "Precision: 0.7516216153828398\n",
      "f1 score: 0.7373331370795169\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Evaluate model metrics\n",
    "\n",
    "accuracy = (TP+TN)/all\n",
    "recall = TP/(TP+FN)\n",
    "precision = TP/(TP+FP)\n",
    "f1_score = 2 * ((precision * recall)/(precision + recall))\n",
    "\n",
    "print(f'Classifer metrics:\\n--------------------\\nAccuracy: {accuracy}\\nRecall: {recall}\\nPrecision: {precision}\\nf1 score: {f1_score}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Apply the model to the new data\n",
    "\n",
    "Use the trained classifier to predict the sentiment of the streamed tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "This is a rubbish tweet!\n",
      "0\n",
      "This is a great tweet!\n",
      "4\n",
      "I don't like mushrooms, they taste horrible\n",
      "0\n",
      "I love mushrooms, they are great\n",
      "4\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "def classify_tweet(tweet_text: str) -> float:\n",
    "    \"\"\"\n",
    "    Predict the sentiment of a tweet by applying test preprocessing\n",
    "    and supplying the preprocessed tweet to the sentiment classifier. \n",
    "    \"\"\"\n",
    "    preprocessed_tokenized_tweet = stem_lemmatize(tokenize_tag(tweet_text))\n",
    "    features = get_features(preprocessed_tokenized_tweet)\n",
    "    return nbclassifier.classify(features)\n",
    "    \n",
    "# Test the classifier\n",
    "test_text = [\"This is a rubbish tweet!\",\n",
    "             \"This is a great tweet!\",\n",
    "             \"I don't like mushrooms, they taste horrible\",\n",
    "             \"I love mushrooms, they are great\"]\n",
    "\n",
    "for sentence in test_text:\n",
    "    print(sentence)\n",
    "    print(classify_tweet(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Apply to tweets in DataFrame.\n",
    "\n",
    "from brexittweets.config import sqlite_db_path\n",
    "from brexittweets.custom_funcs.sqlite_functions import size_of_database, get_data\n",
    "import sqlite3\n",
    "\n",
    "db = sqlite3.connect(sqlite_db_path)\n",
    "cursor = db.cursor()\n",
    "\n",
    "# Get length of the db\n",
    "dbLength = size_of_database(cursor)\n",
    "\n",
    "# Apply sentiment analysis to Tweets in database\n",
    "for index in range(1,dbLength+1):\n",
    "    # Get tweet from the db\n",
    "    tweet = get_data('text', index, cursor)\n",
    "    tweet_sentiment = classify_tweet(tweet)\n",
    "    update_statement = f\"UPDATE tweets SET sentiment={tweet_sentiment} WHERE id = {index};\"\n",
    "    cursor.execute(update_statement)\n",
    "    db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Grab a few Tweets to see how they were classified."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   id                                               text  sentiment_TextBlob\n0   1   Ben Mellor want the Tories out He rocks up su...                 0.0\n1   2  Richard Ayoade doesnt even sound like he belie...                 0.0\n2   3          If sht was chocolate no body would starve                 0.0\n3   4               Let me guess you also voted brexit ?                 4.0\n4   5  Join our webinar with speakers from Hogan Love...                 0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>sentiment_TextBlob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Ben Mellor want the Tories out He rocks up su...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Richard Ayoade doesnt even sound like he belie...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>If sht was chocolate no body would starve</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Let me guess you also voted brexit ?</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Join our webinar with speakers from Hogan Love...</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "from brexittweets.custom_funcs.sqlite_functions import check_sentiment_analysis\n",
    "\n",
    "test_df = check_sentiment_analysis(cursor, 'custom')\n",
    "test_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Close the database\n",
    "db.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "Go, A., Bhayani, R. and Huang, L., 2009. Twitter sentiment \n",
    "classification using distant supervision. CS224N Project Report, Stanford, 1(2009), p.12."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (brexittweetsproject)",
   "language": "python",
   "name": "pycharm-1fb690fb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}